import logging
import os
from typing import TypedDict, Literal, Dict, Any, List, Tuple

import google.generativeai as genai
from dotenv import load_dotenv
from langgraph.graph import StateGraph
from langchain_community.embeddings import GPT4AllEmbeddings
from langchain_community.vectorstores import FAISS
from duckduckgo_search import DDGS

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)
VECTOR_DB_PATH = "data/vectorstores/db_text"
MAX_WEB_RESULTS = 5
MODEL_GEMINI = "gemini-1.5-flash"  # S·ª≠ d·ª•ng model h·ª£p l·ªá

# Load Gemini API key t·ª´ file .env
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

if not api_key:
    raise ValueError("API key GOOGLE_API_KEY ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p trong m√¥i tr∆∞·ªùng ho·∫∑c file .env.")

genai.configure(api_key=api_key)
try:
    routing_model = genai.GenerativeModel(MODEL_GEMINI)
    answering_model = genai.GenerativeModel(MODEL_GEMINI)
    logger.info("ƒê√£ kh·ªüi t·∫°o th√†nh c√¥ng model Gemini.")
except Exception as e:
    logger.error(f"L·ªói kh·ªüi t·∫°o model Gemini: {e}")
    raise

# C·∫≠p nh·∫≠t QAState ƒë·ªÉ l∆∞u l·ªãch s·ª≠ tr√≤ chuy·ªán
class QAState(TypedDict):
    query: str
    result: str | None
    history: List[Tuple[str, str]]  # L∆∞u l·ªãch s·ª≠ d∆∞·ªõi d·∫°ng [(query, result), ...]

# Tool 1: Truy v·∫•n t·ª´ d·ªØ li·ªáu B·ªô T√†i ch√≠nh (FAISS)
def search_ministry(state: QAState) -> Dict[str, Any]:
    logger.info(">>> Running Tool: search_ministry (FAISS)")
    query = state.get("query")
    history = state.get("history", [])
    
    if not query:
        logger.error("search_ministry: No query found in state.")
        return {"result": "L·ªói: Kh√¥ng t√¨m th·∫•y c√¢u h·ªèi trong state."}

    try:
        embedding_model = GPT4AllEmbeddings(model_file="data/models/all-MiniLM-L6-v2-f16.gguf")
        db = FAISS.load_local(VECTOR_DB_PATH, embedding_model, allow_dangerous_deserialization=True)
        logger.info(f"Searching FAISS for: {query}")
        docs = db.similarity_search(query, k=15)
        context = "\n".join([doc.page_content for doc in docs])

        if not context.strip():
            logger.warning("search_ministry: No relevant documents found in FAISS.")
            return {"result": "Kh√¥ng t√¨m th·∫•y t√†i li·ªáu li√™n quan trong c∆° s·ªü d·ªØ li·ªáu B·ªô T√†i ch√≠nh."}

        # Th√™m l·ªãch s·ª≠ v√†o prompt ƒë·ªÉ cung c·∫•p ng·ªØ c·∫£nh
        history_text = "\n".join([f"Ng∆∞·ªùi d√πng: {q}\nTr·ª£ l√Ω: {r}" for q, r in history[-3:]])  # Ch·ªâ l·∫•y 3 l∆∞·ª£t g·∫ßn nh·∫•t ƒë·ªÉ tr√°nh v∆∞·ª£t gi·ªõi h·∫°n token
        prompt = f"""
B·∫°n l√† m·ªôt tr·ª£ l√Ω ph√°p l√Ω th√¢n thi·ªán, am hi·ªÉu vƒÉn b·∫£n ph√°p lu·∫≠t c·ªßa B·ªô T√†i ch√≠nh.
Tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng CH·ªà d·ª±a tr√™n ph·∫ßn "D·ªØ li·ªáu n·ªôi b·ªô" d∆∞·ªõi ƒë√¢y ‚Äî kh√¥ng suy ƒëo√°n hay t·∫°o n·ªôi dung kh√¥ng c√≥ s·∫µn.

- N·∫øu kh√¥ng ƒë·ªß th√¥ng tin, h√£y n√≥i r√µ m·ªôt c√°ch nh√£ nh·∫∑n (v√≠ d·ª•: "D·ª±a theo th√¥ng tin t√¥i c√≥ ƒë∆∞·ª£c...").
- N·∫øu c√¢u h·ªèi ch∆∞a r√µ r√†ng ho·∫∑c qu√° chung chung, h√£y khuy·∫øn kh√≠ch ng∆∞·ªùi d√πng h·ªèi l·∫°i c·ª• th·ªÉ h∆°n.
- Ch·ªâ ƒë·ªÅ c·∫≠p ƒë·∫øn d·ªØ li·ªáu n·ªôi b·ªô, kh√¥ng n√≥i ƒë·∫øn c√°ch c·∫•u tr√∫c ho·∫∑c c√°ch b·∫°n nh·∫≠n ƒë∆∞·ª£c d·ªØ li·ªáu.
- Gi·∫£i th√≠ch g·ªçn, d·ªÖ hi·ªÉu, v√† ƒë√∫ng theo n·ªôi dung t·ª´ B·ªô T√†i ch√≠nh, n·∫øu c·∫ßn h√£y tr√≠ch xu·∫•t t·ª´ ng·ªØ c·∫£nh ƒë∆∞·ª£c cung c·∫•p cho ƒë·∫ßy ƒë·ªß.
- N·∫øu kh√¥ng th·ªÉ x√°c ƒë·ªãnh c√¢u tr·∫£ l·ªùi t·ª´ d·ªØ li·ªáu, h√£y n√≥i r√µ: "T√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong d·ªØ li·ªáu n·ªôi b·ªô."
- N·∫øu ng∆∞·ªùi d√πng y√™u c·∫ßu chi ti·∫øt, h√£y tr·∫£ l·ªùi th·∫≠t chi ti·∫øt t·ª´ n·ªôi dung n·ªôi b·ªô b·∫°n ƒë∆∞·ª£c cung c·∫•p.
- D·ª±a v√†o l·ªãch s·ª≠ tr√≤ chuy·ªán ƒë·ªÉ tr·∫£ l·ªùi m·∫°ch l·∫°c h∆°n n·∫øu c·∫ßn.

L·ªãch s·ª≠ tr√≤ chuy·ªán:
---
{history_text}
---

D·ªØ li·ªáu n·ªôi b·ªô:
---
{context}
---

C√¢u h·ªèi:
{query}

Tr·∫£ l·ªùi:
H√£y cung c·∫•p m·ªôt c√¢u tr·∫£ l·ªùi chi ti·∫øt, r√µ r√†ng, v√† ƒë√∫ng theo c√°c d·ªØ li·ªáu trong ph·∫ßn "D·ªØ li·ªáu n·ªôi b·ªô". N·∫øu c√¢u tr·∫£ l·ªùi kh√¥ng ƒë·∫ßy ƒë·ªß, xin vui l√≤ng l√†m r√µ th√™m v·ªõi c√°c th√¥ng tin m√† b·∫°n c√≥ ƒë∆∞·ª£c t·ª´ d·ªØ li·ªáu.
"""
        logger.info(f"[search_ministry] Prompting Gemini...")
        response = answering_model.generate_content(prompt)
        logger.info(f"[search_ministry] Raw Gemini Response Text: '{response.text}'")
        final_result = response.text.strip()

        if not final_result:
            logger.warning("[search_ministry] Gemini returned empty or whitespace response.")
            return {"result": "Xin l·ªói, t√¥i kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi t·ª´ d·ªØ li·ªáu B·ªô T√†i ch√≠nh t√¨m ƒë∆∞·ª£c."}

        return {"result": final_result}

    except FileNotFoundError:
        logger.error("search_ministry: L·ªói kh√¥ng t√¨m th·∫•y file vectorstores/db_faiss ho·∫∑c model embedding.")
        return {"result": "L·ªói: Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu B·ªô T√†i ch√≠nh. Vui l√≤ng ki·ªÉm tra c√†i ƒë·∫∑t."}
    except Exception as e:
        logger.error(f"L·ªói trong search_ministry: {e}")
        return {"result": "ƒê√£ x·∫£y ra l·ªói khi truy v·∫•n d·ªØ li·ªáu B·ªô T√†i ch√≠nh."}

# Tool 2: T√¨m ki·∫øm DuckDuckGo
def search_web(state: QAState) -> Dict[str, Any]:
    logger.info(">>> Running Tool: search_web (DuckDuckGo)")
    query = state.get("query")
    history = state.get("history", [])
    
    if not query:
        logger.error("search_web: No query found in state.")
        return {"result": "L·ªói: Kh√¥ng t√¨m th·∫•y c√¢u h·ªèi trong state."}

    try:
        logger.info(f"Searching Web (DDGS) for: {query}")
        with DDGS() as ddgs:
            results = list(ddgs.text(query, max_results=MAX_WEB_RESULTS))

        if not results:
            logger.warning("search_web: No results found on DuckDuckGo.")
            return {"result": "Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan tr√™n web."}

        context = "\n".join([
            f"Ti√™u ƒë·ªÅ: {r.get('title', '')}\nN·ªôi dung: {r.get('body', '')}\nNgu·ªìn: {r.get('href', '')}\n---"
            for r in results if r.get('body')
        ]).strip()

        if not context:
            logger.warning("search_web: No content found in DDGS results.")
            return {"result": "Kh√¥ng t√¨m th·∫•y n·ªôi dung c·ª• th·ªÉ t·ª´ k·∫øt qu·∫£ t√¨m ki·∫øm web."}

        # Th√™m l·ªãch s·ª≠ v√†o prompt ƒë·ªÉ cung c·∫•p ng·ªØ c·∫£nh
        history_text = "\n".join([f"Ng∆∞·ªùi d√πng: {q}\nTr·ª£ l√Ω: {r}" for q, r in history[-3:]])
        prompt = f"""
D·ª±a CH·ª¶ Y·∫æU v√†o c√°c k·∫øt qu·∫£ t√¨m ki·∫øm sau ƒë√¢y ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ng·∫Øn g·ªçn v√† ch√≠nh x√°c. Tr√≠ch d·∫´n ngu·ªìn n·∫øu c√≥ th·ªÉ.
- D·ª±a v√†o l·ªãch s·ª≠ tr√≤ chuy·ªán ƒë·ªÉ tr·∫£ l·ªùi m·∫°ch l·∫°c h∆°n n·∫øu c·∫ßn.
- N·∫øu kh√¥ng th·ªÉ x√°c ƒë·ªãnh c√¢u tr·∫£ l·ªùi t·ª´ d·ªØ li·ªáu, h√£y n√≥i r√µ: "T√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong d·ªØ li·ªáu t√¨m ki·∫øm tr√™n web."
- N·∫øu c√¢u h·ªèi ch∆∞a r√µ r√†ng ho·∫∑c qu√° chung chung, h√£y khuy·∫øn kh√≠ch ng∆∞·ªùi d√πng h·ªèi l·∫°i c·ª• th·ªÉ h∆°n.
- Tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng CH·ªà d·ª±a tr√™n ph·∫ßn "K·∫øt qu·∫£ t√¨m ki·∫øm" d∆∞·ªõi ƒë√¢y ‚Äî kh√¥ng suy ƒëo√°n hay t·∫°o n·ªôi dung kh√¥ng c√≥ s·∫µn.

L·ªãch s·ª≠ tr√≤ chuy·ªán:
---
{history_text}
---

K·∫øt qu·∫£ t√¨m ki·∫øm:
---
{context}
---

C√¢u h·ªèi: {query}

Tr·∫£ l·ªùi:
"""
        logger.info(f"[search_web] Prompting Gemini...")
        response = answering_model.generate_content(prompt)
        logger.info(f"[search_web] Raw Gemini Response Text: '{response.text}'")
        final_result = response.text.strip()

        if not final_result:
            logger.warning("[search_web] Gemini returned empty or whitespace response.")
            return {"result": "Xin l·ªói, t√¥i kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi t·ª´ th√¥ng tin t√¨m ki·∫øm ƒë∆∞·ª£c tr√™n web."}

        return {"result": final_result}

    except Exception as e:
        logger.error(f"L·ªói trong search_web: {e}")
        return {"result": "ƒê√£ x·∫£y ra l·ªói khi t√¨m ki·∫øm tr√™n web ho·∫∑c x·ª≠ l√Ω k·∫øt qu·∫£."}

# Node ƒë·ªãnh tuy·∫øn
def route(state: QAState) -> Literal["ministry", "search", "__error__"]:
    logger.info(">>> Running Router Node...")
    query = state.get("query")
    history = state.get("history", [])
    
    if not query:
        logger.error("Router: No query found in state.")
        return "__error__"

    # Th√™m l·ªãch s·ª≠ v√†o prompt ƒë·ªãnh tuy·∫øn ƒë·ªÉ quy·∫øt ƒë·ªãnh ch√≠nh x√°c h∆°n
    history_text = "\n".join([f"Ng∆∞·ªùi d√πng: {q}\nTr·ª£ l√Ω: {r}" for q, r in history[-3:]])
    routing_prompt = f"""
C√¢u h·ªèi sau ƒë√¢y li√™n quan ƒë·∫øn lƒ©nh v·ª±c n√†o?
1. Th√¥ng tin chung c·∫ßn t√¨m tr√™n web ('search')
2. Th√¥ng tin chuy√™n s√¢u v·ªÅ B·ªô T√†i ch√≠nh Vi·ªát Nam, vƒÉn b·∫£n, quy ƒë·ªãnh ('ministry')

L·ªãch s·ª≠ tr√≤ chuy·ªán (n·∫øu c√≥):
---
{history_text}
---

C√¢u h·ªèi: "{query}"

Tr·∫£ l·ªùi CH√çNH X√ÅC b·∫±ng m·ªôt trong hai t·ª´: 'search' ho·∫∑c 'ministry'.
"""
    logger.info("Router: Asking routing_model...")
    try:
        response = routing_model.generate_content(routing_prompt)
        choice = response.text.strip().lower()
        logger.info(f"Router: LLM raw response: '{choice}'")

        if "ministry" in choice:
            logger.info("Router: Decision -> ministry")
            return "ministry"
        elif "search" in choice:
            logger.info("Router: Decision -> search")
            return "search"
        else:
            logger.warning(f"Router: Could not determine route from response '{choice}'. Defaulting to 'search'.")
            return "search"

    except Exception as e:
        logger.error(f"Router: Error during routing API call: {e}")
        logger.warning("Router: Error occurred. Defaulting to 'search'.")
        return "search"

# LangGraph Graph setup
workflow = StateGraph(QAState)

# C·∫≠p nh·∫≠t state ƒë·ªÉ bao g·ªìm l·ªãch s·ª≠
def update_state_with_history(state: QAState, new_result: Dict[str, Any]) -> QAState:
    current_history = state.get("history", [])
    new_history = current_history + [(state["query"], new_result["result"])]
    return {**state, **new_result, "history": new_history}

workflow.add_node("ministry", lambda s: update_state_with_history(s, search_ministry(s)))
workflow.add_node("search", lambda s: update_state_with_history(s, search_web(s)))
workflow.add_node("handle_error", lambda s: update_state_with_history(s, {"result": "Xin l·ªói, t√¥i kh√¥ng th·ªÉ ph√¢n lo·∫°i c√¢u h·ªèi c·ªßa b·∫°n."}))

workflow.set_conditional_entry_point(
    route,
    {
        "ministry": "ministry",
        "search": "search",
        "__error__": "handle_error",
    }
)

workflow.add_edge("ministry", "__end__")
workflow.add_edge("search", "__end__")
workflow.add_edge("handle_error", "__end__")

# Bi√™n d·ªãch graph
try:
    app = workflow.compile()
    logger.info("LangGraph compiled successfully.")
except Exception as e:
    logger.error(f"Error compiling LangGraph: {e}")
    raise

# Run Q&A bot v·ªõi l·ªãch s·ª≠
if __name__ == "__main__":
    logger.info("Starting Q&A Bot...")
    conversation_history: List[Tuple[str, str]] = []  # L∆∞u l·ªãch s·ª≠ to√†n b·ªô cu·ªôc tr√≤ chuy·ªán
    state: QAState = {"query": "", "result": None, "history": []}  # Tr·∫°ng th√°i ban ƒë·∫ßu

    while True:
        try:
            question = input("‚ùì H√£y nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n (ho·∫∑c g√µ 'quit' ƒë·ªÉ tho√°t): ")
            if question.lower() == 'quit':
                break
            if not question.strip():
                print("Vui l√≤ng nh·∫≠p c√¢u h·ªèi.")
                continue

            # C·∫≠p nh·∫≠t tr·∫°ng th√°i v·ªõi c√¢u h·ªèi m·ªõi
            state = {**state, "query": question, "history": conversation_history}
            logger.info(f"Invoking graph with query: '{question}'")

            # Ch·∫°y graph
            final_state = app.invoke(state)
            logger.info(f"Graph execution finished. Final state: {final_state}")

            # C·∫≠p nh·∫≠t l·ªãch s·ª≠ tr√≤ chuy·ªán
            result = final_state.get('result', 'Kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi cu·ªëi c√πng.')
            conversation_history.append((question, result))
            state = final_state  # C·∫≠p nh·∫≠t tr·∫°ng th√°i cho l·∫ßn l·∫∑p ti·∫øp theo

            # In k·∫øt qu·∫£
            print("-" * 20)
            print(f"üìç Tr·∫£ l·ªùi: {result}")
            print("-" * 20 + "\n")

        except Exception as e:
            logger.exception("An error occurred during the main execution loop:")
            print(f"\nüí• ƒê√£ c√≥ l·ªói x·∫£y ra: {e}")

    logger.info("Q&A Bot stopped.")